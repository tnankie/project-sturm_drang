{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import scipy as sci\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global vars\n",
    "samp_rt = 5120 #sampling rate Hz\n",
    "time_import = 3000 # time to analyse seconds\n",
    "data_import = samp_rt * time_import # lines of data to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_list(big_list, lil_size):\n",
    "    l_o_l = []\n",
    "    for i in range(0, len(big_list), lil_size):\n",
    "        lil = big_list[i : min(i + lil_size, len(big_list))]\n",
    "        l_o_l.append(lil)\n",
    "    return(l_o_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_analysis(sample , ttime, responsefrq =1, sampfrq = 5120):\n",
    "#     mmtic = time.perf_counter()\n",
    "    frqs = \"\"\n",
    "    amps = []\n",
    "    samp_int = 1/sampfrq\n",
    "    ft = np.fft.fft(sample)/len(sample)\n",
    "#     mmhic = time.perf_counter()\n",
    "    ft = ft[range(int(len(sample)/2))]\n",
    "    tpCount = len(sample)\n",
    "    values = np.arange(int(tpCount/2))\n",
    "    timePeriod = tpCount/sampfrq\n",
    "    frequencies = values/timePeriod\n",
    "    ft = abs(ft)\n",
    "#     mmcup = time.perf_counter()\n",
    "    #print(len(ft))\n",
    "    #print(len(frequencies))\n",
    "    feq = pd.DataFrame(data = {\"freq\":frequencies})\n",
    "#     l1 = time.perf_counter()\n",
    "    feq[\"amp\"] = ft\n",
    "#     l2 = time.perf_counter()\n",
    "    frqs = np.arange(0, 1 + int(feq.freq.max()), responsefrq)\n",
    "#     l3 = time.perf_counter()\n",
    "    #print(len(frqs))\n",
    "#     mmbless = time.perf_counter()\n",
    "    wow = feq.amp.rolling(10).mean()\n",
    "    yep = np.arange(responsefrq - 1, len(wow) + responsefrq  -1, responsefrq)\n",
    "    amps = wow[yep]\n",
    "#     l4 = time.perf_counter()\n",
    "#     mmtoc = time.perf_counter()\n",
    "#     print(\"init:\", mmhic-mmtic)\n",
    "#     print(\"fft:\", mmcup - mmhic, \"total:\", mmcup - mmtic)\n",
    "#     print(\"df1:\", mmbless - mmcup, \"total:\", mmbless - mmtic)\n",
    "#     print(\"done:\", mmtoc - mmbless, \"total:\", mmtoc - mmtic)\n",
    "#     print(\"l1, l2, l3, l4:\", l1-mmcup, l2-mmcup, l3-mmcup, l4-mmcup)\n",
    "#     print(\"for:\", l4 - l3)\n",
    "    return(frqs, amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5, 9, 13, 17, 21, 25, 29]]\n"
     ]
    }
   ],
   "source": [
    "test_list  = list(range(1,33,4))\n",
    "test_chop = 9\n",
    "print(list_o_list(test_list, test_chop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.idea',\n",
       " '.ipynb_checkpoints',\n",
       " 'alt_modular.py',\n",
       " 'bayesian_optimiser_tute.py',\n",
       " 'capstone2_milestone 2.ipynb',\n",
       " 'checkpoint.pth',\n",
       " 'data',\n",
       " 'data_prep.ipynb',\n",
       " 'data_prep_development.ipynb',\n",
       " 'data_prep_final.ipynb',\n",
       " 'EDA.ipynb',\n",
       " 'EDA2.ipynb',\n",
       " 'eda2_b.ipynb',\n",
       " 'EDA3.ipynb',\n",
       " 'Figure 2020-11-08 143412.png',\n",
       " 'Figure 2020-11-08 143421.png',\n",
       " 'gps_inclusion.ipynb',\n",
       " 'init_lstm_epoch_10.dat',\n",
       " 'init_lstm_optim_state_epoch_10.dat',\n",
       " 'init_lstm_state_epoch_10.dat',\n",
       " 'linear_LSTM.py',\n",
       " 'lstm.ipynb',\n",
       " 'lstm2.py',\n",
       " 'lstm2_data_prep.py',\n",
       " 'lstm2_data_prep_double_sensor.py',\n",
       " 'LSTM_classes.py',\n",
       " 'LSTM_classes_functions.py',\n",
       " 'lstm_examples.py',\n",
       " 'lstm_model_01.py',\n",
       " 'LSTM_modular.py',\n",
       " 'LSTM_modular_combined.py',\n",
       " 'LSTM_modular_two_sensor.py',\n",
       " 'lstm_multivariate_working.py',\n",
       " 'lstm_network.py',\n",
       " 'LSTM_pipeline.py',\n",
       " 'LSTM_sentiment_test.py',\n",
       " 'lstm_training.ipynb',\n",
       " 'main.py',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'testing_Conv1D.ipynb',\n",
       " 'torch_loader_tute.py',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " 'Working_train_nn-Copy1.ipynb',\n",
       " 'Working_train_nn.ipynb',\n",
       " 'Working_train_nn_conv-Copy1.ipynb',\n",
       " 'Working_train_nn_conv-Copy2.ipynb',\n",
       " 'Working_train_nn_conv.ipynb',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Grey Ghost\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\data\\\\08-14-18-V118'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"./data/08-14-18-V118\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "csv_files = []\n",
    "for n in files:\n",
    "    if re.search(\".csv\", n):\n",
    "        csv_files.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.hubstorinfo', '08-14-18-V118_ch1.csv', '08-14-18-V118_ch2.csv', 'ft_first_3000.csv']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_files[0], header=15, names=[\"time\", \"acceleration_a\"], nrows = data_import)\n",
    "df.head()\n",
    "df2 = pd.read_csv(csv_files[1], header=15, names=[\"time\", \"acceleration_b\"], nrows = data_import)\n",
    "df2.head()\n",
    "raw = pd.merge(left=df, right=df2, how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15360000 entries, 0 to 15359999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   time            float64\n",
      " 1   acceleration_a  float64\n",
      " 2   acceleration_b  float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 468.8 MB\n"
     ]
    }
   ],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_a = list(raw.acceleration_a)\n",
    "acc_b = list(raw.acceleration_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list_o_list(acc_a, 5120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = list_o_list(acc_b, 5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 7.9006414000000404\n"
     ]
    }
   ],
   "source": [
    "tic_a = time.perf_counter()\n",
    "ft_l1 = []\n",
    "frq_l1 = []\n",
    "for i in l1:\n",
    "    frq_l1, amp = freq_analysis(i, 1, 10, samp_rt)\n",
    "    ft_l1.append(amp)\n",
    "toc_a = time.perf_counter()\n",
    "print(\"time diff:\", toc_a - tic_a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 7.300061699999787\n"
     ]
    }
   ],
   "source": [
    "tic_b = time.perf_counter()\n",
    "ft_l2 = []\n",
    "frq_l2 = []\n",
    "count = 0\n",
    "for i in l2:\n",
    "#     mtic = time.perf_counter()\n",
    "    frq_l2, amp = freq_analysis(i, 1, 10, samp_rt)\n",
    "    ft_l2.append(amp)\n",
    "#     mtoc = time.perf_counter()\n",
    "#     print(count, mtoc-mtic)\n",
    "    count += 1\n",
    "toc_b = time.perf_counter()\n",
    "print(\"time diff:\", toc_b - tic_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frq_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ft_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ft_l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ = {}\n",
    "for c,v in enumerate(frq_l1):\n",
    "#     print(c , v)\n",
    "    value = []\n",
    "    for i in ft_l1:\n",
    "#         print(i)\n",
    "        value.append(i.iloc[c])\n",
    "    key = str(v) + \"_a\"\n",
    "    dic_[key] = value\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,v in enumerate(frq_l2):\n",
    "    value = []\n",
    "    for i in ft_l1:\n",
    "        value.append(i.iloc[c])\n",
    "    key =  str(v) + \"_b\"\n",
    "    dic_[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0_a', '10_a', '20_a', '30_a', '40_a', '50_a', '60_a', '70_a', '80_a', '90_a', '100_a', '110_a', '120_a', '130_a', '140_a', '150_a', '160_a', '170_a', '180_a', '190_a', '200_a', '210_a', '220_a', '230_a', '240_a', '250_a', '260_a', '270_a', '280_a', '290_a', '300_a', '310_a', '320_a', '330_a', '340_a', '350_a', '360_a', '370_a', '380_a', '390_a', '400_a', '410_a', '420_a', '430_a', '440_a', '450_a', '460_a', '470_a', '480_a', '490_a', '500_a', '510_a', '520_a', '530_a', '540_a', '550_a', '560_a', '570_a', '580_a', '590_a', '600_a', '610_a', '620_a', '630_a', '640_a', '650_a', '660_a', '670_a', '680_a', '690_a', '700_a', '710_a', '720_a', '730_a', '740_a', '750_a', '760_a', '770_a', '780_a', '790_a', '800_a', '810_a', '820_a', '830_a', '840_a', '850_a', '860_a', '870_a', '880_a', '890_a', '900_a', '910_a', '920_a', '930_a', '940_a', '950_a', '960_a', '970_a', '980_a', '990_a', '1000_a', '1010_a', '1020_a', '1030_a', '1040_a', '1050_a', '1060_a', '1070_a', '1080_a', '1090_a', '1100_a', '1110_a', '1120_a', '1130_a', '1140_a', '1150_a', '1160_a', '1170_a', '1180_a', '1190_a', '1200_a', '1210_a', '1220_a', '1230_a', '1240_a', '1250_a', '1260_a', '1270_a', '1280_a', '1290_a', '1300_a', '1310_a', '1320_a', '1330_a', '1340_a', '1350_a', '1360_a', '1370_a', '1380_a', '1390_a', '1400_a', '1410_a', '1420_a', '1430_a', '1440_a', '1450_a', '1460_a', '1470_a', '1480_a', '1490_a', '1500_a', '1510_a', '1520_a', '1530_a', '1540_a', '1550_a', '1560_a', '1570_a', '1580_a', '1590_a', '1600_a', '1610_a', '1620_a', '1630_a', '1640_a', '1650_a', '1660_a', '1670_a', '1680_a', '1690_a', '1700_a', '1710_a', '1720_a', '1730_a', '1740_a', '1750_a', '1760_a', '1770_a', '1780_a', '1790_a', '1800_a', '1810_a', '1820_a', '1830_a', '1840_a', '1850_a', '1860_a', '1870_a', '1880_a', '1890_a', '1900_a', '1910_a', '1920_a', '1930_a', '1940_a', '1950_a', '1960_a', '1970_a', '1980_a', '1990_a', '2000_a', '2010_a', '2020_a', '2030_a', '2040_a', '2050_a', '2060_a', '2070_a', '2080_a', '2090_a', '2100_a', '2110_a', '2120_a', '2130_a', '2140_a', '2150_a', '2160_a', '2170_a', '2180_a', '2190_a', '2200_a', '2210_a', '2220_a', '2230_a', '2240_a', '2250_a', '2260_a', '2270_a', '2280_a', '2290_a', '2300_a', '2310_a', '2320_a', '2330_a', '2340_a', '2350_a', '2360_a', '2370_a', '2380_a', '2390_a', '2400_a', '2410_a', '2420_a', '2430_a', '2440_a', '2450_a', '2460_a', '2470_a', '2480_a', '2490_a', '2500_a', '2510_a', '2520_a', '2530_a', '2540_a', '2550_a', '0_b', '10_b', '20_b', '30_b', '40_b', '50_b', '60_b', '70_b', '80_b', '90_b', '100_b', '110_b', '120_b', '130_b', '140_b', '150_b', '160_b', '170_b', '180_b', '190_b', '200_b', '210_b', '220_b', '230_b', '240_b', '250_b', '260_b', '270_b', '280_b', '290_b', '300_b', '310_b', '320_b', '330_b', '340_b', '350_b', '360_b', '370_b', '380_b', '390_b', '400_b', '410_b', '420_b', '430_b', '440_b', '450_b', '460_b', '470_b', '480_b', '490_b', '500_b', '510_b', '520_b', '530_b', '540_b', '550_b', '560_b', '570_b', '580_b', '590_b', '600_b', '610_b', '620_b', '630_b', '640_b', '650_b', '660_b', '670_b', '680_b', '690_b', '700_b', '710_b', '720_b', '730_b', '740_b', '750_b', '760_b', '770_b', '780_b', '790_b', '800_b', '810_b', '820_b', '830_b', '840_b', '850_b', '860_b', '870_b', '880_b', '890_b', '900_b', '910_b', '920_b', '930_b', '940_b', '950_b', '960_b', '970_b', '980_b', '990_b', '1000_b', '1010_b', '1020_b', '1030_b', '1040_b', '1050_b', '1060_b', '1070_b', '1080_b', '1090_b', '1100_b', '1110_b', '1120_b', '1130_b', '1140_b', '1150_b', '1160_b', '1170_b', '1180_b', '1190_b', '1200_b', '1210_b', '1220_b', '1230_b', '1240_b', '1250_b', '1260_b', '1270_b', '1280_b', '1290_b', '1300_b', '1310_b', '1320_b', '1330_b', '1340_b', '1350_b', '1360_b', '1370_b', '1380_b', '1390_b', '1400_b', '1410_b', '1420_b', '1430_b', '1440_b', '1450_b', '1460_b', '1470_b', '1480_b', '1490_b', '1500_b', '1510_b', '1520_b', '1530_b', '1540_b', '1550_b', '1560_b', '1570_b', '1580_b', '1590_b', '1600_b', '1610_b', '1620_b', '1630_b', '1640_b', '1650_b', '1660_b', '1670_b', '1680_b', '1690_b', '1700_b', '1710_b', '1720_b', '1730_b', '1740_b', '1750_b', '1760_b', '1770_b', '1780_b', '1790_b', '1800_b', '1810_b', '1820_b', '1830_b', '1840_b', '1850_b', '1860_b', '1870_b', '1880_b', '1890_b', '1900_b', '1910_b', '1920_b', '1930_b', '1940_b', '1950_b', '1960_b', '1970_b', '1980_b', '1990_b', '2000_b', '2010_b', '2020_b', '2030_b', '2040_b', '2050_b', '2060_b', '2070_b', '2080_b', '2090_b', '2100_b', '2110_b', '2120_b', '2130_b', '2140_b', '2150_b', '2160_b', '2170_b', '2180_b', '2190_b', '2200_b', '2210_b', '2220_b', '2230_b', '2240_b', '2250_b', '2260_b', '2270_b', '2280_b', '2290_b', '2300_b', '2310_b', '2320_b', '2330_b', '2340_b', '2350_b', '2360_b', '2370_b', '2380_b', '2390_b', '2400_b', '2410_b', '2420_b', '2430_b', '2440_b', '2450_b', '2460_b', '2470_b', '2480_b', '2490_b', '2500_b', '2510_b', '2520_b', '2530_b', '2540_b', '2550_b'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = dic_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Columns: 512 entries, 0_a to 2550_b\n",
      "dtypes: float64(512)\n",
      "memory usage: 11.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>10_a</th>\n",
       "      <th>20_a</th>\n",
       "      <th>30_a</th>\n",
       "      <th>40_a</th>\n",
       "      <th>50_a</th>\n",
       "      <th>60_a</th>\n",
       "      <th>70_a</th>\n",
       "      <th>80_a</th>\n",
       "      <th>90_a</th>\n",
       "      <th>...</th>\n",
       "      <th>2460_b</th>\n",
       "      <th>2470_b</th>\n",
       "      <th>2480_b</th>\n",
       "      <th>2490_b</th>\n",
       "      <th>2500_b</th>\n",
       "      <th>2510_b</th>\n",
       "      <th>2520_b</th>\n",
       "      <th>2530_b</th>\n",
       "      <th>2540_b</th>\n",
       "      <th>2550_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017958</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.015724</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.247093</td>\n",
       "      <td>0.053908</td>\n",
       "      <td>0.089252</td>\n",
       "      <td>0.099943</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>0.086571</td>\n",
       "      <td>0.136009</td>\n",
       "      <td>0.149118</td>\n",
       "      <td>0.159840</td>\n",
       "      <td>0.181195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>0.032938</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>0.067473</td>\n",
       "      <td>0.030790</td>\n",
       "      <td>0.030223</td>\n",
       "      <td>0.031847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0_a         10_a         20_a         30_a         40_a  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      0.010199     0.004577     0.007899     0.009146     0.010439   \n",
       "std       0.017958     0.004757     0.008208     0.010071     0.012105   \n",
       "min       0.000708     0.000469     0.000419     0.000505     0.000420   \n",
       "25%       0.002385     0.001399     0.001553     0.001558     0.001591   \n",
       "50%       0.003362     0.003216     0.005669     0.006285     0.007233   \n",
       "75%       0.006740     0.005870     0.011421     0.012362     0.013786   \n",
       "max       0.247093     0.053908     0.089252     0.099943     0.121408   \n",
       "\n",
       "              50_a         60_a         70_a         80_a         90_a  ...  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000  ...   \n",
       "mean      0.008746     0.010328     0.011205     0.010931     0.008534  ...   \n",
       "std       0.009777     0.011111     0.015724     0.015432     0.012300  ...   \n",
       "min       0.000395     0.000555     0.000262     0.000139     0.000186  ...   \n",
       "25%       0.001505     0.004286     0.001180     0.000889     0.000837  ...   \n",
       "50%       0.005940     0.006212     0.005680     0.005850     0.004720  ...   \n",
       "75%       0.011685     0.012353     0.013855     0.013888     0.010956  ...   \n",
       "max       0.086571     0.136009     0.149118     0.159840     0.181195  ...   \n",
       "\n",
       "            2460_b       2470_b       2480_b       2490_b       2500_b  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      0.002639     0.002620     0.002711     0.002738     0.002649   \n",
       "std       0.002940     0.003035     0.003161     0.003244     0.002898   \n",
       "min       0.000072     0.000116     0.000082     0.000082     0.000088   \n",
       "25%       0.000540     0.000463     0.000475     0.000443     0.000478   \n",
       "50%       0.001807     0.001793     0.001780     0.001819     0.001793   \n",
       "75%       0.003588     0.003614     0.003803     0.003870     0.003859   \n",
       "max       0.031867     0.032938     0.038900     0.032661     0.026856   \n",
       "\n",
       "            2510_b       2520_b       2530_b       2540_b       2550_b  \n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000  \n",
       "mean      0.002868     0.002847     0.002526     0.002478     0.002432  \n",
       "std       0.003353     0.003523     0.002790     0.002734     0.002799  \n",
       "min       0.000103     0.000099     0.000080     0.000082     0.000047  \n",
       "25%       0.000733     0.000705     0.000524     0.000549     0.000491  \n",
       "50%       0.001838     0.001783     0.001691     0.001675     0.001693  \n",
       "75%       0.003805     0.003757     0.003521     0.003391     0.003289  \n",
       "max       0.046754     0.067473     0.030790     0.030223     0.031847  \n",
       "\n",
       "[8 rows x 512 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ft_first_\" + str(time_import) + \".csv\"\n",
    "df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22727068 0.03550042]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df)\n",
    "print(pca.explained_variance_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_scores = []\n",
    "for i in np.arange(1,100):\n",
    "    pca_n = PCA(n_components = i)\n",
    "    pca_n.fit(df)\n",
    "    p_scores.append(sum(pca_n.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sb.scatterplot(x=np.arange(1,100), y=p_scores, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 7.906452899999749\n"
     ]
    }
   ],
   "source": [
    "tic_a = time.perf_counter()\n",
    "ft_l1 = []\n",
    "frq_l1 = []\n",
    "for i in l1:\n",
    "    frq_l1, amp = freq_analysis(i, 1, 1, samp_rt)\n",
    "    ft_l1.append(amp)\n",
    "toc_a = time.perf_counter()\n",
    "print(\"time diff:\", toc_a - tic_a)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 9.53600920000008\n"
     ]
    }
   ],
   "source": [
    "tic_b = time.perf_counter()\n",
    "ft_l2 = []\n",
    "frq_l2 = []\n",
    "count = 0\n",
    "for i in l2:\n",
    "#     mtic = time.perf_counter()\n",
    "    frq_l2, amp = freq_analysis(i, 1, 1, samp_rt)\n",
    "    ft_l2.append(amp)\n",
    "#     mtoc = time.perf_counter()\n",
    "#     print(count, mtoc- mtic)\n",
    "    count += 1\n",
    "toc_b = time.perf_counter()\n",
    "print(\"time diff:\", toc_b - tic_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_1 = {}\n",
    "for c,v in enumerate(frq_l1):\n",
    "    value = []\n",
    "    for i in ft_l1:\n",
    "        value.append(i.iloc[c])\n",
    "    key = str(v) + \"_a\"\n",
    "    dic_1[key] = value\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,v in enumerate(frq_l2):\n",
    "    value = []\n",
    "    for i in ft_l1:\n",
    "        value.append(i[c])\n",
    "    key =  str(v) + \"_b\"\n",
    "    dic_1[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>1_a</th>\n",
       "      <th>2_a</th>\n",
       "      <th>3_a</th>\n",
       "      <th>4_a</th>\n",
       "      <th>5_a</th>\n",
       "      <th>6_a</th>\n",
       "      <th>7_a</th>\n",
       "      <th>8_a</th>\n",
       "      <th>9_a</th>\n",
       "      <th>...</th>\n",
       "      <th>2550_b</th>\n",
       "      <th>2551_b</th>\n",
       "      <th>2552_b</th>\n",
       "      <th>2553_b</th>\n",
       "      <th>2554_b</th>\n",
       "      <th>2555_b</th>\n",
       "      <th>2556_b</th>\n",
       "      <th>2557_b</th>\n",
       "      <th>2558_b</th>\n",
       "      <th>2559_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_a  1_a  2_a  3_a  4_a  5_a  6_a  7_a  8_a       9_a  ...    2550_b  \\\n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.002120  ...  0.000623   \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.002151  ...  0.000592   \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.001390  ...  0.000503   \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.001914  ...  0.000543   \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.001099  ...  0.000603   \n",
       "\n",
       "     2551_b    2552_b    2553_b    2554_b    2555_b    2556_b    2557_b  \\\n",
       "0  0.000610  0.000610  0.000626  0.000603  0.000505  0.000611  0.000620   \n",
       "1  0.000634  0.000634  0.000563  0.000658  0.000611  0.000536  0.000529   \n",
       "2  0.000500  0.000576  0.000615  0.000722  0.000662  0.000707  0.000703   \n",
       "3  0.000505  0.000463  0.000435  0.000470  0.000487  0.000500  0.000441   \n",
       "4  0.000651  0.000622  0.000520  0.000452  0.000436  0.000404  0.000469   \n",
       "\n",
       "     2558_b    2559_b  \n",
       "0  0.000665  0.000644  \n",
       "1  0.000558  0.000557  \n",
       "2  0.000672  0.000629  \n",
       "3  0.000470  0.000482  \n",
       "4  0.000440  0.000547  \n",
       "\n",
       "[5 rows x 5120 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(data = dic_1)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-891ff9ddbf6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpca_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpca_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mp_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \"\"\"\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[0;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "p_scores_1 = []\n",
    "for i in np.arange(1,100):\n",
    "    pca_n = PCA(n_components = i)\n",
    "    pca_n.fit(df_1)\n",
    "    p_scores.append(sum(pca_n.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sb.scatterplot(x=np.arange(1,100), y=p_scores_1, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_scores_1 = []\n",
    "for i in np.arange(1,1000):\n",
    "    pca_n = PCA(n_components = i)\n",
    "    pca_n.fit(df_1)\n",
    "    p_scores.append(sum(pca_n.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sb.scatterplot(x=np.arange(1,1000), y=p_scores_1, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
