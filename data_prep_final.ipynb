{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import scipy as sci\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global vars\n",
    "samp_rt = 5120 #sampling rate Hz\n",
    "time_import = 3000 # time to analyse, seconds\n",
    "data_import = samp_rt * time_import # lines of data to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_list(big_list, lil_size):\n",
    "    l_o_l = []\n",
    "    for i in range(0, len(big_list), lil_size):\n",
    "        lil = big_list[i : min(i + lil_size, len(big_list))]\n",
    "        l_o_l.append(lil)\n",
    "    return(l_o_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_analysis(sample , ttime, responsefrq =1, sampfrq = 5120):\n",
    "#     mmtic = time.perf_counter()\n",
    "    frqs = \"\"\n",
    "    amps = []\n",
    "    samp_int = 1/sampfrq\n",
    "    ft = np.fft.fft(sample)/len(sample)\n",
    "#     mmhic = time.perf_counter()\n",
    "    ft = ft[range(int(len(sample)/2))]\n",
    "    tpCount = len(sample)\n",
    "    values = np.arange(int(tpCount/2))\n",
    "    timePeriod = tpCount/sampfrq\n",
    "    frequencies = values/timePeriod\n",
    "    ft = abs(ft)\n",
    "#     mmcup = time.perf_counter()\n",
    "    #print(len(ft))\n",
    "    #print(len(frequencies))\n",
    "    feq = pd.DataFrame(data = {\"freq\":frequencies})\n",
    "#     l1 = time.perf_counter()\n",
    "    feq[\"amp\"] = ft\n",
    "#     l2 = time.perf_counter()\n",
    "    frqs = np.arange(0, 1 + int(feq.freq.max()), responsefrq)\n",
    "#     l3 = time.perf_counter()\n",
    "    #print(len(frqs))\n",
    "#     mmbless = time.perf_counter()\n",
    "    wow = feq.amp.rolling(responsefrq).mean()\n",
    "    yep = np.arange(responsefrq - 1, len(wow) + responsefrq  -1, responsefrq)\n",
    "    amps = wow[yep]\n",
    "#     l4 = time.perf_counter()\n",
    "#     mmtoc = time.perf_counter()\n",
    "#     print(\"init:\", mmhic-mmtic)\n",
    "#     print(\"fft:\", mmcup - mmhic, \"total:\", mmcup - mmtic)\n",
    "#     print(\"df1:\", mmbless - mmcup, \"total:\", mmbless - mmtic)\n",
    "#     print(\"done:\", mmtoc - mmbless, \"total:\", mmtoc - mmtic)\n",
    "#     print(\"l1, l2, l3, l4:\", l1-mmcup, l2-mmcup, l3-mmcup, l4-mmcup)\n",
    "#     print(\"for:\", l4 - l3)\n",
    "    return(frqs, amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file):\n",
    "    df = pd.read_csv(file.path, header=15, names=[\"time\", \"acceleration\"], nrows = data_import)\n",
    "    \n",
    "    l1 = list(df.acceleration)\n",
    "    \n",
    "    \n",
    "    l2 = list_o_list(l1, 5120)\n",
    "    del l1\n",
    "    \n",
    "    bin_size = 10\n",
    "    tot_frqs = int((samp_rt / 2) / bin_size)\n",
    "    tic_a = time.perf_counter()\n",
    "    ft_l1 = np.empty((time_import, tot_frqs))\n",
    "    frq_l1 = np.empty(tot_frqs, np.int8)\n",
    "    for c,v in enumerate(l2):\n",
    "        frq_l1, amp = freq_analysis(v, 1, bin_size, samp_rt) # 1 is the total time of the sample (1 second)\n",
    "        ft_l1[c] = amp\n",
    "    toc_a = time.perf_counter()\n",
    "    print(\"time diff:\", toc_a - tic_a)\n",
    "    direct = pd.DataFrame(data = ft_l1, columns = frq_l1)\n",
    "    l2_df = pd.DataFrame(data =l2)\n",
    "    del l2\n",
    "    direct[\"mean_acc\"] = l2_df.abs().mean(axis=1)\n",
    "    direct[\"median\"] = l2_df.abs().median(axis=1)\n",
    "    direct[\"95_acc\"] = l2_df.abs().quantile(.95)\n",
    "    direct[\"max_acc\"] = l2_df.abs().max(axis=1)\n",
    "    del l2_df\n",
    "    file_name = file.name[:-3] + \"dat\"\n",
    "    direct.to_csv(file_name)\n",
    "    toe = time.perf_counter()\n",
    "    print(\"Finished in:\", toe - tic_a, \"seconds\")\n",
    "    return()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\.git', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\.ipynb_checkpoints', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\01-08-19-V118', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\03-05-19-V118', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\03-26-19-V118', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\08-14-18-V118', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\GPS Files', 'C:\\\\Users\\\\tnank\\\\Documents\\\\GitHub\\\\project-sturm_drang\\\\Test Train Sample Noise Data']\n"
     ]
    }
   ],
   "source": [
    "os.listdir()\n",
    "home = os.getcwd()\n",
    "dirs = []\n",
    "dirs.append(home)\n",
    "with os.scandir(home) as contents:\n",
    "    for i in contents:\n",
    "        if i.is_dir():\n",
    "            dirs.append(i.path)\n",
    "print(dirs)\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-08-19-V118_ch1.csv\n",
      "time diff: 19.801157200000034\n",
      "Finished in: 31.698206500000197 seconds\n",
      "01-08-19-V118_ch2.csv\n",
      "time diff: 20.166382200000044\n",
      "Finished in: 31.723734400000012 seconds\n",
      "REC0001_ch1.csv\n",
      "time diff: 20.14995500000032\n",
      "Finished in: 31.777458200000183 seconds\n",
      "REC0001_ch2.csv\n",
      "time diff: 19.99009309999974\n",
      "Finished in: 31.35782479999989 seconds\n",
      "REC0002_ch1.csv\n",
      "time diff: 19.79238400000031\n",
      "Finished in: 31.294547600000442 seconds\n",
      "REC0002_ch2.csv\n",
      "time diff: 20.032706799999687\n",
      "Finished in: 31.60263489999943 seconds\n",
      "08-14-18-V118_ch1.csv\n",
      "time diff: 19.991257900000164\n",
      "Finished in: 31.678287000000637 seconds\n",
      "08-14-18-V118_ch2.csv\n"
     ]
    }
   ],
   "source": [
    "for i in dirs:\n",
    "    \n",
    "    with os.scandir(i) as stuff:\n",
    "        for thing in stuff:\n",
    "            if re.search(\".csv\", thing.name) and re.search(\"_ch\\d\", thing.name):\n",
    "                print(thing.name)\n",
    "                process(thing)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
